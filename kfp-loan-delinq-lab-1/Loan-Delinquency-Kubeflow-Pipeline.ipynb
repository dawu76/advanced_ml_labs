{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeFlow Pipeline: Loan-Delinquency Model\n",
    "\n",
    "This notebook assumes that you have already set up a GKE cluster with Kubeflow installed as per this codelab: [g.co/codelabs/kubecon18](g.co/codelabs/kubecon18). Currently, this notebook must be run from the Kubeflow JupyterHub installation, as described in the codelab.\n",
    "\n",
    "In this notebook, we will show how to:\n",
    "\n",
    "* Interactively define a KubeFlow Pipeline using the Pipelines Python SDK\n",
    "* Submit and run the pipeline\n",
    "* Add a step in the pipeline\n",
    "\n",
    "This example pipeline is composed of 4 steps:\n",
    "1. Create train and eval split from a dataset\n",
    "2. Perform hyper parmeter tuning for a basic tensorflow model on CMLE \n",
    "3. Train this model with best hyperparameters\n",
    "4. Deploy this model on CMLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some imports and set some variables.  Set the `WORKING_DIR` to a path under the Cloud Storage bucket you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp  # the Pipelines SDK.  This library is included with the notebook image.\n",
    "from kfp import compiler\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp\n",
    "import kfp.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some pipeline input variables. \n",
    "BUCKET_NAME = 'test-gcp-demo' # No gs:// here.\n",
    "\n",
    "WORKING_DIR = 'gs://' + BUCKET_NAME +  'loan-delinq/notebooks' # Such as gs://bucket/object/path\n",
    "PROJECT_ID = 'test-gcp-02-224508'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an *Experiment* in the Kubeflow Pipeline System\n",
    "\n",
    "The Kubeflow Pipeline system requires an \"Experiment\" to group pipeline runs. You can create a new experiment, or call `client.list_experiments()` to get existing ones.\n",
    "\n",
    "### Note that this notebook should be running in JupyterHub in the same cluster as the pipeline system, Otherwise it will fail to talk to the pipeline system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': [{'created_at': datetime.datetime(2019, 3, 2, 2, 21, 46, tzinfo=tzlocal()),\n",
       "                  'description': None,\n",
       "                  'id': 'b7fe0a9d-78bb-4b15-819f-0dc1560cf3dd',\n",
       "                  'name': 'ex'},\n",
       "                 {'created_at': datetime.datetime(2019, 3, 2, 2, 39, 18, tzinfo=tzlocal()),\n",
       "                  'description': None,\n",
       "                  'id': '1a6fbdd0-8556-42d6-8107-0ce6b136d791',\n",
       "                  'name': 'ex1'},\n",
       "                 {'created_at': datetime.datetime(2019, 3, 2, 5, 5, 28, tzinfo=tzlocal()),\n",
       "                  'description': None,\n",
       "                  'id': '19d416c5-d570-402e-a8a8-1e0b4f6bc838',\n",
       "                  'name': 'ex1-1'},\n",
       "                 {'created_at': datetime.datetime(2019, 3, 5, 20, 3, 53, tzinfo=tzlocal()),\n",
       "                  'description': None,\n",
       "                  'id': 'a1ccb473-f60a-4afc-8235-0ed499a0111b',\n",
       "                  'name': 'exp_gtc'},\n",
       "                 {'created_at': datetime.datetime(2019, 3, 5, 22, 18, 4, tzinfo=tzlocal()),\n",
       "                  'description': None,\n",
       "                  'id': '7dd81b4e-c283-4f27-b4d8-2be058355042',\n",
       "                  'name': 'ex-2-name'},\n",
       "                 {'created_at': datetime.datetime(2019, 3, 8, 18, 49, 45, tzinfo=tzlocal()),\n",
       "                  'description': None,\n",
       "                  'id': 'e92d1f39-1766-43fd-859a-0671b072cf9e',\n",
       "                  'name': 'datagen_notebook'}],\n",
       " 'next_page_token': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/40dc366f-e9aa-4891-9d9a-1006bb6df934\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp = client.create_experiment(name='datagen_notebook-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Pipeline\n",
    "\n",
    "Authoring a pipeline is like authoring a normal Python function. The pipeline function describes the topology of the pipeline. \n",
    "\n",
    "Each step in the pipeline is typically a `ContainerOp` --- a simple class or function describing how to interact with a docker container image. In the pipeline, all the container images referenced in the pipeline are already built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dsl.pipeline(\n",
    "  name='Loan Delinquency',\n",
    "  description='Demonstrate a tensorflow pipeline for Loan-Delinquency Classification'\n",
    ")\n",
    "def loan_delinq_pipeline (\n",
    "  project: dsl.PipelineParam=dsl.PipelineParam(name='project', value='test-gcp-02-224508'),\n",
    "  bucketName: dsl.PipelineParam=dsl.PipelineParam(name='bucketName', value='test-gcp-demo')   \n",
    "  ):\n",
    "    preprocess = dsl.ContainerOp(\n",
    "      name='trainevalsplit',\n",
    "      # image needs to be a compile-time string\n",
    "      image='gcr.io/test-gcp-02-224508/loan-pipeline-trainevalsplit:latest',\n",
    "      arguments=[\n",
    "        '--project', project,\n",
    "        '--bucket', bucketName\n",
    "      ],\n",
    "      file_outputs={'bucket': '/output.txt'}\n",
    "    ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    hparam_train = dsl.ContainerOp(\n",
    "      name='hypertrain',\n",
    "      # image needs to be a compile-time string\n",
    "      image='gcr.io/test-gcp-02-224508/loan-pipeline-hptune:latest',\n",
    "      arguments=[\n",
    "                  '--bucket', bucketName,\n",
    "                   '--kfp'\n",
    "      ],\n",
    "      file_outputs={'jobname': '/output.txt'}\n",
    "    ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    \n",
    "    \n",
    "    train_tuned = dsl.ContainerOp(\n",
    "      name='trainTFtuned',\n",
    "      # image needs to be a compile-time string\n",
    "      image='gcr.io/test-gcp-02-224508/loan-pipeline-trainmodel:latest',\n",
    "\n",
    "      arguments=[\n",
    "          '--bucket', bucketName,\n",
    "          '--hyperjob', hparam_train.outputs['jobname'],\n",
    "                   '--kfp'\n",
    "      ],\n",
    "      file_outputs={'train': '/output.txt'}\n",
    "    ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    \n",
    "    train_tuned.set_memory_request('2G')\n",
    "    train_tuned.set_cpu_request('1')\n",
    "    \n",
    "    \n",
    "    deploy_cmle = dsl.ContainerOp(\n",
    "      name='deploytfmodel',\n",
    "      # image needs to be a compile-time string\n",
    "      image='gcr.io/test-gcp-02-224508/loan-pipeline-deploytfmodel:latest',\n",
    "      arguments=[\n",
    "        '--modeldir', train_tuned.outputs['train'],  # modeldir\n",
    "        '--modelname'  , 'loandelinquency',\n",
    "        '--modelversion', 'v1',\n",
    "                   '--kfp'\n",
    "      ],\n",
    "      file_outputs={\n",
    "        'model': '/model.txt',\n",
    "        'version': '/version.txt'\n",
    "      }\n",
    "    )\n",
    "    hparam_train.after(preprocess)\n",
    "    train_tuned.after(hparam_train)\n",
    "    deploy_cmle.after(train_tuned)\n",
    "  #train.set_gpu_limit(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit an experiment *run*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(loan_delinq_pipeline, 'loan_delinq_pipeline.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call below will run the compiled pipeline.  We won't actually do that now, but instead we'll add a new step to the pipeline, then run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/99ac32b9-420e-11e9-9640-42010a8a00eb\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#You'd uncomment this call to actually run the pipeline. \n",
    "run = client.run_pipeline(exp.id, 'loan_delinq_pipeline', 'loan_delinq_pipeline.tar.gz',\n",
    "                          params={'bucketName': BUCKET_NAME,\n",
    "                                   'project': PROJECT_ID})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pipeline execution finishes you should see something like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline GUI ](./pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "Copyright 2018 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
